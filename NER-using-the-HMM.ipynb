{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5dd3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "with open(\"PATH\",encoding=\"utf8\") as fh:\n",
    "    train_lines = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a775891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuple each tagged word inside a list\n",
    "array_tutucu=[]\n",
    "t_tutucu=[]\n",
    "for asa in train_lines:\n",
    "    k=asa.split()\n",
    "    array_tutucu.append(k)\n",
    "for a in array_tutucu:\n",
    "    tu=tuple(a)\n",
    "    t_tutucu.append(tu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85741117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ATİLLA', 'B-PERSON'), ('Mutman', 'I-PERSON'), (',', 'O'), ('İzmir', 'B-LOCATION'), ('milletvekili', 'O'), (), ('Gecenin', 'O'), ('erken', 'O'), ('saatlerinde', 'O'), ('de', 'O'), (',', 'O'), ('belli', 'O'), ('olacak', 'O'), ('Avrupa', 'B-LOCATION'), (\"'\", 'O'), ('nın', 'O'), ('en', 'O'), ('büyük', 'O'), ('ülkesinin', 'O'), ('hükümetini', 'O'), ('kimin', 'O'), ('yöneteceği', 'O'), (), ('Bilgisayarlı', 'O'), ('telefon', 'O'), ('klübesi', 'O'), (), ('Kozmopolit', 'O'), ('bir', 'O'), ('ulus', 'O'), (), ('Yıllık', 'O'), ('10', 'O'), ('milyon', 'O'), ('ton', 'O'), ('kapasitesi', 'O'), ('bulunan', 'O'), ('limana', 'O'), ('150', 'O'), ('bin', 'O'), ('DWT', 'O'), ('tonluk', 'O'), ('gemiler', 'O'), ('yanaşabilecek', 'O'), (), ('Uzanan', 'O'), ('bir', 'O'), ('\"', 'O'), ('barış', 'O'), ('eli', 'O')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(t_tutucu[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ae7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tur_array=[]\n",
    "genel_array=[]\n",
    "for sss in t_tutucu:\n",
    "    if len(sss)!=0:\n",
    "        tur_array.append(sss)\n",
    "    else :\n",
    "        genel_array.append(tur_array)\n",
    "        tur_array=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa1f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ATİLLA', 'Mutman', ',', 'İzmir', 'milletvekili', 'Gecenin', 'erken', 'saatlerinde', 'de', ',')\n",
      "('B-PERSON', 'I-PERSON', 'O', 'B-LOCATION', 'O', 'O', 'O', 'O', 'O', 'O')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token=[]\n",
    "entity=[]\n",
    "i=0\n",
    "for genel in genel_array:\n",
    "    for tl in genel:\n",
    "        if len(tl)==2:\n",
    "            token.append(tl[0])\n",
    "            entity.append(tl[1])\n",
    "    \n",
    "tokens=tuple(token)\n",
    "entity=tuple(entity) \n",
    "print(tokens[0:10])\n",
    "print(entity[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579ea8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the number of word tags at the beginning of the sentence and calculating the probability of their being found\n",
    "b_location=0\n",
    "b_organization=0\n",
    "b_person=1\n",
    "i_location=0\n",
    "i_organization=0\n",
    "i_person=0\n",
    "o=0\n",
    "for i in range(len(t_tutucu)-1):\n",
    "    if len(t_tutucu[i]) < 2:\n",
    "        if t_tutucu[i+1][1] == \"B-LOCATION\":\n",
    "            b_location+=1\n",
    "        elif t_tutucu[i+1][1] == \"B-ORGANIZATION\":\n",
    "            b_organization+=1\n",
    "        elif t_tutucu[i+1][1] == \"B-PERSON\":\n",
    "            b_person+=1\n",
    "        elif t_tutucu[i+1][1] == \"I-LOCATION\":\n",
    "            i_location+=1\n",
    "        elif t_tutucu[i+1][1] == \"I-ORGANIZATION\":\n",
    "            i_organization+=1\n",
    "        elif t_tutucu[i+1][1] == \"I-PERSON\":\n",
    "            i_person+=1\n",
    "        elif t_tutucu[i+1][1] == \"O\":\n",
    "            o+=1\n",
    "sum=b_location+b_organization+b_person+i_location+i_organization+i_person+o    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbdcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = pos_tag(sentence.split())\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(WordNetLemmatizer().lemmatize(word, tag))\n",
    "    return lemmatized_sentence   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c166e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens                 \"         $         %         &         '         (  \\\n",
      "entity                                                                       \n",
      "B-LOCATION      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-ORGANIZATION  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-PERSON        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-LOCATION      0.000000  0.000000  0.000000  0.000000  0.003115  0.000000   \n",
      "I-ORGANIZATION  0.000000  0.000000  0.000000  0.002730  0.004949  0.000000   \n",
      "I-PERSON        0.000634  0.000000  0.000000  0.000000  0.001267  0.000000   \n",
      "O               0.023062  0.000003  0.000027  0.000024  0.046473  0.003584   \n",
      "\n",
      "tokens                )         +         ,         -  ...   şüpheyi  \\\n",
      "entity                                                 ...             \n",
      "B-LOCATION      0.00000  0.000000  0.000000  0.000000  ...  0.000000   \n",
      "B-ORGANIZATION  0.00000  0.000000  0.000000  0.000000  ...  0.000000   \n",
      "B-PERSON        0.00000  0.000000  0.000075  0.000000  ...  0.000000   \n",
      "I-LOCATION      0.00000  0.000000  0.002336  0.010903  ...  0.000000   \n",
      "I-ORGANIZATION  0.00000  0.000000  0.001536  0.020307  ...  0.000000   \n",
      "I-PERSON        0.00000  0.000000  0.000000  0.003801  ...  0.000000   \n",
      "O               0.00344  0.000027  0.061742  0.006764  ...  0.000003   \n",
      "\n",
      "tokens          şüpnhelenilen     şüyuu       şıh       şık    şıklık  \\\n",
      "entity                                                                  \n",
      "B-LOCATION           0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-ORGANIZATION       0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-PERSON             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-LOCATION           0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-ORGANIZATION       0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-PERSON             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "O                    0.000003  0.000003  0.000003  0.000021  0.000003   \n",
      "\n",
      "tokens           şımarık    şırnak  şırnaklı         ’  \n",
      "entity                                                  \n",
      "B-LOCATION      0.000000  0.002267  0.000000  0.000000  \n",
      "B-ORGANIZATION  0.000000  0.000000  0.000000  0.000000  \n",
      "B-PERSON        0.000000  0.000000  0.000000  0.000000  \n",
      "I-LOCATION      0.000000  0.000000  0.000000  0.000000  \n",
      "I-ORGANIZATION  0.000000  0.000000  0.000000  0.000000  \n",
      "I-PERSON        0.000000  0.000000  0.000000  0.000000  \n",
      "O               0.000003  0.000000  0.000003  0.000005  \n",
      "\n",
      "[7 rows x 56184 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating emission matrix\n",
    "tokens = [lemmatize_sentence(token.lower())[0] for token in tokens]\n",
    "\n",
    "df = pd.DataFrame(tokens,entity).reset_index().rename(columns={0:'tokens','index':'entity'})\n",
    "df['values']=1\n",
    "df = df.pivot_table(index='entity',columns='tokens',aggfunc='sum').fillna(0)\n",
    "df = df.div(df.sum(axis=1), axis=0)\n",
    "df.columns = df.columns.droplevel(0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297a64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B-LOCATION  I-LOCATION         O  B-ORGANIZATION  B-PERSON  \\\n",
      "<s>               0.073462    0.000000  0.704629        0.094637  0.127272   \n",
      "B-LOCATION        0.006657    0.105103  0.885788        0.001985  0.000467   \n",
      "B-ORGANIZATION    0.008235    0.000000  0.601792        0.002786  0.000484   \n",
      "B-PERSON          0.002650    0.000000  0.555126        0.001363  0.005982   \n",
      "I-LOCATION        0.007843    0.301176  0.687059        0.000784  0.003137   \n",
      "I-ORGANIZATION    0.004281    0.000000  0.535616        0.002568  0.000856   \n",
      "I-PERSON          0.003838    0.000000  0.896028        0.003338  0.001502   \n",
      "O                 0.019638    0.000000  0.933962        0.017229  0.029171   \n",
      "\n",
      "                I-ORGANIZATION  I-PERSON  \n",
      "<s>                   0.000000  0.000000  \n",
      "B-LOCATION            0.000000  0.000000  \n",
      "B-ORGANIZATION        0.386702  0.000000  \n",
      "B-PERSON              0.000000  0.434878  \n",
      "I-LOCATION            0.000000  0.000000  \n",
      "I-ORGANIZATION        0.456678  0.000000  \n",
      "I-PERSON              0.000000  0.095294  \n",
      "O                     0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "#Creating transition matrix\n",
    "df2 = []\n",
    "for index in range(len(t_tutucu)-1):\n",
    "    if len(t_tutucu[index+1]) ==2 and len(t_tutucu[index]) ==2 :\n",
    "        first_token = t_tutucu[index][1]\n",
    "        next_token = t_tutucu[index+1][1]\n",
    "        df2.append({'first_token':first_token,'next_token':next_token})\n",
    "df2 = pd.DataFrame(df2)\n",
    "df2['values'] = 1\n",
    "df2 = df2.pivot_table(index='first_token',columns='next_token',aggfunc='sum').fillna(0)\n",
    "df2 = df2.div(df2.sum(axis=1), axis=0)\n",
    "df2.columns = df2.columns.droplevel(0)\n",
    "df2 = pd.concat([pd.DataFrame(columns=['B-LOCATION','I-LOCATION','O','B-ORGANIZATION','B-PERSON','I-ORGANIZATION','I-PERSON'],index=['<s>'],data=[[b_location/sum,i_location/sum,o/sum,b_organization/sum,b_person/sum,i_organization/sum,i_person/sum]]),df2],axis=0)\n",
    "\n",
    "print(df2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc06ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PATH\",encoding=\"utf8\") as fh:\n",
    "    test_lines = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1dc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49600\n"
     ]
    }
   ],
   "source": [
    "array_tutucu=[]\n",
    "t_tutucu=[]\n",
    "m_test=[]\n",
    "for asa in test_lines:\n",
    "    k=asa.split()\n",
    "    array_tutucu.append(k)\n",
    "for x in array_tutucu:\n",
    "    if len(x) ==2:\n",
    "        m_test.append(x[1])\n",
    "print(len(m_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16c6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "testMetin=\"\"\n",
    "for test in array_tutucu:\n",
    "    if len(test)==2:\n",
    "        testMetin = testMetin + test[0] +\" \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "404c9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1= testMetin\n",
    "list_of_entity = []\n",
    "previous = \"<s>\"\n",
    "tokens = [lemmatize_sentence(token.lower())[0] for token in word_tokenize(test_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a1d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "  \n",
    "#Tokens that don't exist in transition matrix assigned random values\n",
    "dat = [[0.01], [0.01], [0.01],[0.01], [0.01], [0.01],[0.01]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df3 = pd.DataFrame(dat, columns=['Word'])\n",
    "  \n",
    "for token in tokens:\n",
    "    if token in list(df.columns.values):\n",
    "        matrix = df[token].multiply(df2.loc[previous])\n",
    "        previous = df.index[np.argmax(matrix)]\n",
    "        token_label_pair = (token,previous)\n",
    "        list_of_entity.append(token_label_pair)\n",
    "    else:\n",
    "        matrix = df3[\"Word\"].multiply(df2.loc[previous])\n",
    "        previous = df.index[np.argmax(matrix)]\n",
    "        token_label_pair = (token,previous)\n",
    "        list_of_entity.append(token_label_pair)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4201897",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "for x in list_of_entity:\n",
    "    if len(x) ==2:\n",
    "        pred.append(x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca56d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49600\n",
      "49600\n"
     ]
    }
   ],
   "source": [
    "print(len(m_test))\n",
    "print(len(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bd3d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    B-LOCATION       0.79      0.86      0.82      1126\n",
      "B-ORGANIZATION       0.85      0.55      0.67       873\n",
      "      B-PERSON       0.89      0.75      0.81      1603\n",
      "    I-LOCATION       0.75      0.33      0.46       211\n",
      "I-ORGANIZATION       0.63      0.15      0.24       864\n",
      "      I-PERSON       0.91      0.52      0.67       803\n",
      "             O       0.96      1.00      0.98     44120\n",
      "\n",
      "      accuracy                           0.95     49600\n",
      "     macro avg       0.83      0.59      0.66     49600\n",
      "  weighted avg       0.95      0.95      0.94     49600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(m_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0cb3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another test data\n",
    "with open(\"PATH\",encoding=\"utf8\") as fh:\n",
    "    test_lines = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d440c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45532\n"
     ]
    }
   ],
   "source": [
    "array_tutucu=[]\n",
    "t_tutucu=[]\n",
    "m_test=[]\n",
    "for asa in test_lines:\n",
    "    k=asa.split()\n",
    "    array_tutucu.append(k)\n",
    "for x in array_tutucu:\n",
    "    if len(x) ==2:\n",
    "        m_test.append(x[1])\n",
    "print(len(m_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83334e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "testMetin=\"\"\n",
    "for test in array_tutucu:\n",
    "    if len(test)==2:\n",
    "        testMetin = testMetin + test[0] +\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6724d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1= testMetin\n",
    "list_of_entity = []\n",
    "previous = \"<s>\"\n",
    "tokens = [lemmatize_sentence(token.lower())[0] for token in word_tokenize(test_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e42a7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "  \n",
    "# initialize list of lists\n",
    "dat = [[0.01], [0.01], [0.01],[0.01], [0.01], [0.01],[0.01]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df3 = pd.DataFrame(dat, columns=['Word'])\n",
    "  \n",
    "for token in tokens:\n",
    "    if token in list(df.columns.values):\n",
    "        matrix = df[token].multiply(df2.loc[previous])\n",
    "        previous = df.index[np.argmax(matrix)]\n",
    "        token_label_pair = (token,previous)\n",
    "        list_of_entity.append(token_label_pair)\n",
    "    else:\n",
    "        matrix = df3[\"Word\"].multiply(df2.loc[previous])\n",
    "        previous = df.index[np.argmax(matrix)]\n",
    "        token_label_pair = (token,previous)\n",
    "        list_of_entity.append(token_label_pair)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9df3d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "for x in list_of_entity:\n",
    "    if len(x) ==2:\n",
    "        pred.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e70400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45532\n",
      "45532\n"
     ]
    }
   ],
   "source": [
    "print(len(m_test))\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d12c8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    B-LOCATION       0.81      0.92      0.86       942\n",
      "B-ORGANIZATION       0.87      0.66      0.75       842\n",
      "      B-PERSON       0.90      0.86      0.88      1400\n",
      "    I-LOCATION       0.68      0.53      0.60       107\n",
      "I-ORGANIZATION       0.68      0.25      0.37       589\n",
      "      I-PERSON       0.90      0.68      0.77       680\n",
      "             O       0.98      0.99      0.99     40972\n",
      "\n",
      "      accuracy                           0.97     45532\n",
      "     macro avg       0.83      0.70      0.75     45532\n",
      "  weighted avg       0.96      0.97      0.96     45532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(m_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ab8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
